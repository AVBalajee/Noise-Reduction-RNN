{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AVBalajee/Noise-Reduction-RNN/blob/main/Noise_Reduction_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qDLOSNff-PkS"
      },
      "source": [
        "## Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "COMJZRsp4Z68"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Conv1D,Conv1DTranspose,Concatenate,Input\n",
        "import numpy as np\n",
        "import IPython.display\n",
        "import glob\n",
        "from tqdm.notebook import tqdm\n",
        "import librosa.display\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DDmaRb9vMrHr"
      },
      "outputs": [],
      "source": [
        "!mkdir \"CleanData\"\n",
        "!mkdir \"NoisyData\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip  '/content/drive/MyDrive/Colab Notebooks/DS_10283_1942.zip'"
      ],
      "metadata": {
        "id": "wp8x7kFouly7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "metadata": {
        "id": "b7KotaV8ux3A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7QN0I2deMrHs"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir \"NoisyTest\"\n",
        "!unzip \"/content/noisy_testset_wav.zip\" -d \"NoisyTest\""
      ],
      "metadata": {
        "id": "a1Znew3q3h3o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir \"CleanTest\"\n",
        "!unzip \"/content/clean_testset_wav.zip\" -d \"CleanTest\""
      ],
      "metadata": {
        "id": "wRIU_b5139Bd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!unzip \"/content/clean_trainset_wav.zip\" -d \"CleanData\"\n",
        "!unzip \"/content/noisy_trainset_wav.zip\" -d \"NoisyData\"\n"
      ],
      "metadata": {
        "id": "n2PpIPGZej0J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-PnK8ImC-XJJ"
      },
      "source": [
        "## Load the Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2kRjDbp7og1u"
      },
      "outputs": [],
      "source": [
        "clean_sounds = glob.glob('/content/CleanData/*')\n",
        "noisy_sounds = glob.glob('/content/NoisyData/*')\n",
        "\n",
        "clean_sounds_list,_ = tf.audio.decode_wav(tf.io.read_file(clean_sounds[0]),desired_channels=1)\n",
        "for i in tqdm(clean_sounds[1:]):\n",
        "  so,_ = tf.audio.decode_wav(tf.io.read_file(i),desired_channels=1)\n",
        "  clean_sounds_list = tf.concat((clean_sounds_list,so),0)\n",
        "\n",
        "noisy_sounds_list,_ = tf.audio.decode_wav(tf.io.read_file(noisy_sounds[0]),desired_channels=1)\n",
        "for i in tqdm(noisy_sounds[1:]):\n",
        "  so,_ = tf.audio.decode_wav(tf.io.read_file(i),desired_channels=1)\n",
        "  noisy_sounds_list = tf.concat((noisy_sounds_list,so),0)\n",
        "\n",
        "clean_sounds_list.shape,noisy_sounds_list.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VtGLQqpjtoQ9"
      },
      "outputs": [],
      "source": [
        "batching_size = 12000\n",
        "\n",
        "clean_train,noisy_train = [],[]\n",
        "\n",
        "for i in tqdm(range(0,clean_sounds_list.shape[0]-batching_size,batching_size)):\n",
        "  clean_train.append(clean_sounds_list[i:i+batching_size])\n",
        "  noisy_train.append(noisy_sounds_list[i:i+batching_size])\n",
        "\n",
        "clean_train = tf.stack(clean_train)\n",
        "noisy_train = tf.stack(noisy_train)\n",
        "\n",
        "clean_train.shape,noisy_train.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LmHBymBD-c40"
      },
      "source": [
        "# Create a tf.data.Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gqos-Og3RaW3"
      },
      "outputs": [],
      "source": [
        "def get_dataset(x_train,y_train):\n",
        "  dataset = tf.data.Dataset.from_tensor_slices((x_train,y_train))\n",
        "  dataset = dataset.shuffle(100).batch(64,drop_remainder=True)\n",
        "  return dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Aj0dzPFPRnVN"
      },
      "outputs": [],
      "source": [
        "train_dataset = get_dataset(noisy_train[:40000],clean_train[:40000])\n",
        "test_dataset = get_dataset(noisy_train[40000:],clean_train[40000:])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9iHY-qn3-hgD"
      },
      "source": [
        "## Reviewing Sample Waveform"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oLQW37WL_siJ"
      },
      "outputs": [],
      "source": [
        "librosa.display.waveshow(np.squeeze(clean_train[5].numpy(),axis=-1))\n",
        "plt.show()\n",
        "librosa.display.waveshow(np.squeeze(noisy_train[5].numpy(),axis=-1))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KXzSSy9x-pEL"
      },
      "source": [
        "## Creating the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ml--SqD2_2xd"
      },
      "outputs": [],
      "source": [
        "inp = Input(shape=(batching_size,1))\n",
        "c1 = Conv1D(2,32,2,'same',activation='relu')(inp)\n",
        "c2 = Conv1D(4,32,2,'same',activation='relu')(c1)\n",
        "c3 = Conv1D(8,32,2,'same',activation='relu')(c2)\n",
        "c4 = Conv1D(16,32,2,'same',activation='relu')(c3)\n",
        "c5 = Conv1D(32,32,2,'same',activation='relu')(c4)\n",
        "\n",
        "dc1 = Conv1DTranspose(32,32,1,padding='same')(c5)\n",
        "conc = Concatenate()([c5,dc1])\n",
        "dc2 = Conv1DTranspose(16,32,2,padding='same')(conc)\n",
        "conc = Concatenate()([c4,dc2])\n",
        "dc3 = Conv1DTranspose(8,32,2,padding='same')(conc)\n",
        "conc = Concatenate()([c3,dc3])\n",
        "dc4 = Conv1DTranspose(4,32,2,padding='same')(conc)\n",
        "conc = Concatenate()([c2,dc4])\n",
        "dc5 = Conv1DTranspose(2,32,2,padding='same')(conc)\n",
        "conc = Concatenate()([c1,dc5])\n",
        "dc6 = Conv1DTranspose(1,32,2,padding='same')(conc)\n",
        "conc = Concatenate()([inp,dc6])\n",
        "dc7 = Conv1DTranspose(1,32,1,padding='same',activation='linear')(conc)\n",
        "model = tf.keras.models.Model(inp,dc7)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d3KErc8hLYRT"
      },
      "outputs": [],
      "source": [
        "tf.keras.utils.plot_model(model,show_shapes=True,show_layer_names=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eEoQNlfE-rfg"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zp8vdzMNCPCG"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer=tf.keras.optimizers.Adam(0.002),loss=tf.keras.losses.MeanAbsoluteError())\n",
        "history = model.fit(train_dataset,epochs=20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-A0Zptah-vFn"
      },
      "source": [
        "## Testing Samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U4ICZpFHd7rN"
      },
      "outputs": [],
      "source": [
        "from IPython.display import Audio\n",
        "Audio(np.squeeze(noisy_train[6].numpy()),rate=16000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xpgmrTe-5xKp"
      },
      "outputs": [],
      "source": [
        "Audio(tf.squeeze(model.predict(tf.expand_dims(tf.expand_dims(noisy_train[6],-1),0))),rate=16000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SPc0TkhnVz_k"
      },
      "outputs": [],
      "source": [
        "model.evaluate(test_dataset)   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t_db-0TA8qin"
      },
      "outputs": [],
      "source": [
        "model.save('NoiseSuppressionModel.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pY_9K-7fTePl"
      },
      "source": [
        "# Inference\n",
        "\n",
        "Handling different sized audio inputs can be solved by overlapping prediction frames and removing the intersection part from the final waveform"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "woHCvozZTcnZ"
      },
      "outputs": [],
      "source": [
        "def get_audio(path):\n",
        "  audio,_ = tf.audio.decode_wav(tf.io.read_file(path),1)\n",
        "  return audio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M37jgkjKTcpw"
      },
      "outputs": [],
      "source": [
        "def inference_preprocess(path):\n",
        "  audio = get_audio(path)\n",
        "  audio_len = audio.shape[0]\n",
        "  batches = []\n",
        "  for i in range(0,audio_len-batching_size,batching_size):\n",
        "    batches.append(audio[i:i+batching_size])\n",
        "\n",
        "  batches.append(audio[-batching_size:])\n",
        "  diff = audio_len - (i + batching_size)\n",
        "  return tf.stack(batches), diff"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zD6oM7-HTcsY"
      },
      "outputs": [],
      "source": [
        "def predict(path):\n",
        "  test_data,diff = inference_preprocess(path)\n",
        "  predictions = model.predict(test_data)\n",
        "  final_op = tf.reshape(predictions[:-1],((predictions.shape[0]-1)*predictions.shape[1],1))\n",
        "  final_op = tf.concat((final_op,predictions[-1][-diff:]),axis=0)\n",
        "  return final_op"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rHHOVxJpVhIB"
      },
      "outputs": [],
      "source": [
        "Audio(np.squeeze(get_audio(noisy_sounds[4]).numpy(),-1),rate=16000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GTnF3fkVTcuK"
      },
      "outputs": [],
      "source": [
        "Audio(tf.squeeze(predict(noisy_sounds[4])),rate=16000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mbyvI5E-uRaG"
      },
      "outputs": [],
      "source": [
        "%%timeit\n",
        "tf.squeeze(predict(noisy_sounds[3]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rI6mrFx-X-g1"
      },
      "outputs": [],
      "source": [
        "librosa.display.waveplot(np.squeeze(get_audio(noisy_sounds[4]).numpy(),-1))\n",
        "librosa.display.waveplot(np.squeeze(predict(noisy_sounds[4])))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "private_outputs": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}